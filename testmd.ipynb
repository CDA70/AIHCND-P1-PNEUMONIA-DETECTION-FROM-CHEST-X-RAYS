{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FDA  Submission\n",
    "\n",
    "**Your Name:** Chris DAEMS\n",
    "\n",
    "**Name of your Device:** Pneumonia Detection Assistant\n",
    "\n",
    "## Algorithm Description \n",
    "\n",
    "### 1. General Information\n",
    "\n",
    "**Intended Use Statement:** The intended use is to assist radiologist detect pneumonia by examaning x-ray images.\n",
    "\n",
    "**Indications for Use:** The algorithm screens x-ray images of patients up to 120 Years. The patients can be both male or female and the results are balanced out well. The images must be of an x-ray type and the body part must be CHEST. As it images must be x-ray therefore the modality must be equal to 'DX' and the body postion must be 'AP' or ' PA'\n",
    "\n",
    "**Device Limitations:** Running the algorithm requires a GPU and therefore it's not suitable in an emergency setting. \n",
    "\n",
    "**Clinical Impact of Performance:** Precision is: 49%, Recall is: 80.0%, F1 Score is: 61%, and Accuracy is: 73%. \n",
    "Although we see that the recall value is high and therefore the false positive rate might also be high, it still is a good assistent for the radiologist. \n",
    "\n",
    "### 2. Algorithm Design and Function\n",
    "\n",
    "![Image of DICOM Workflow](images/Dicom_Workflow.png)\n",
    "\n",
    "**DICOM Checking Steps:**\n",
    "* Patient Age < 120\n",
    "* Patient examined body part = 'CHEST'\n",
    "* Patient Position = 'PA' - Post Anteriot or 'AP' - Anterior Post\n",
    "* Image modality = 'DX'\n",
    "\n",
    "**Preprocessing Steps:** Read the image and resize to (224, 224)\n",
    "\n",
    "**CNN Architecture:** The CNN base network is VGG16 pre-trained on imagenet (https://keras.io/api/applications/vgg/#vgg16-function)\n",
    "\n",
    "![Image of CNN Architecture](images/CNN_Architecture.PNG)\n",
    "\n",
    "\n",
    "### 3. Algorithm Training\n",
    "\n",
    "**Parameters:**\n",
    "* Types of augmentation used during training:\n",
    "    * horizontal_flip = True \n",
    "    * vertical_flip = False \n",
    "    * height_shift_range = 0.1 (10% max)\n",
    "    * width_shift_range =0.1 (10% max)\n",
    "    * rotation_range =10 (degrees)\n",
    "    * shear_range = 0.1 (10% max)\n",
    "    * zoom_range=0.1 (10% max)\n",
    "    \n",
    "    \n",
    "* Batch size: Training batch size = 32\n",
    "\n",
    "* Optimizer learning rate: Adam(lr=1e-3), I also retrained using Adam(lr=1e-4) and Adam(lr=1e-6)\n",
    "\n",
    "* Layers of pre-existing architecture that were frozen: 17 layers were frozen\n",
    "\n",
    "* Layers of pre-existing architecture that were fine-tuned: block5_pool\n",
    "\n",
    "* Layers added to pre-existing architecture\n",
    "    * Flatten()\n",
    "    * Dropout(0.5)\n",
    "    * Dense(1024, activation='relu')\n",
    "    * Dropout(0.5)\n",
    "    * Dense(512, activation='relu')\n",
    "    * Dropout(0.5)\n",
    "    * Dense(256, activation='relu')\n",
    "    * Dropout(0.5)\n",
    "    * Dense(1, activation='sigmoid')\n",
    "\n",
    "**Adam(lr=1e-3)**\n",
    "![Image of trng loss and accuracy](images/traininglossandaccuracy1e3.png)\n",
    "The Training loss and acuracy doesn't seem to be very stable.\n",
    "\n",
    "\n",
    "Now we train the model with a slower training rate to see if it improves the model.\n",
    "\n",
    "**Adam(lr=1e-4)**\n",
    "![Image of trng loss and accuracy](images/traininglossandaccuracy1e4.png)\n",
    "\n",
    "**Adam(lr=1e-6)**\n",
    "![Image of trng loss and accuracy](images/traininglossandaccuracy1e6.png)\n",
    "Using Adam(lr=1e-4) did not improve the validation loss and neither did Adam(lr=1e-6)\n",
    "But it seems that the training loss and validation loss ended up at the same level, while the validation accuracy really dropped after some epochs.  \n",
    "\n",
    "![Image of AUC](images/AUC.PNG)\n",
    "\n",
    "![Image of precision recall](images/precision_recall.PNG)\n",
    "\n",
    "![Image of precision recall](images/precrecallf1score.png)\n",
    "\n",
    "\n",
    "**Final Threshold and Explanation:**\n",
    "As first you see the F1 score\n",
    "![Image of F1](images/F1_score.PNG)\n",
    "\n",
    "The next image show the confusion matrix where we can clearly see the TP, TN, FP and FN values\n",
    "![Image of confusion matrix](images/confusionmatrix.png)\n",
    "\n",
    "As a summary the model performs as follows:\n",
    "![Image of summary](images/summarynumbers.PNG)\n",
    "\n",
    "![Image of True vs Predicted](images/truevspredictedxrays.png)\n",
    "\n",
    "### 4. Databases\n",
    "The data set labels didn't only included Pneumonia, moreover the percentage of pnemonia is rather small\n",
    "* Atelectasis           0.103095\n",
    "* Cardiomegaly          0.024759\n",
    "* Consolidation         0.041625\n",
    "* Edema                 0.020540\n",
    "* Effusion              0.118775\n",
    "* Emphysema             0.022440\n",
    "* Fibrosis              0.015037\n",
    "* Hernia                0.002025\n",
    "* Infiltration          0.177435\n",
    "* Mass                  0.051570\n",
    "* No Finding            0.538361\n",
    "* Nodule                0.056466\n",
    "* Pleural_Thickening    0.030191\n",
    "* **Pneumonia             0.012763**\n",
    "* Pneumothorax          0.047289\n",
    "\n",
    "The balance between Male and Female with pneumonia is fairly balanced\n",
    "![Image of gender with pneumonia](images/genderwihpneumonia.png)\n",
    "\n",
    "There were some outliers in the ages of the patients, but skipping the outliers the ages are as follows. \n",
    "![Image of ages](images/patientages.png)\n",
    "\n",
    "and the ages of patients with only pneumonia\n",
    "![Image of ages of patients with only pneumonia](images/patientageswithpneumonia.png)\n",
    "\n",
    "The following graph also shows that there are other labels then only pneumonia\n",
    "![Image of not only pneumonia](images/pneumonia1.png)\n",
    "\n",
    "The following graph shows the most prevalent combinations wih pneumonia\n",
    "![Image of combination](images/combinepneumonia.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Description of Training Dataset:** \n",
    "The NIH dataset was not specifically acquired for pneumonia. So, while this is a representation of 'pneumonia in the wild,' the prevalence of pneumonia may be different if you were to take only chest x-rays that were acquired in an ER setting with suspicion of pneumonia. But nevertheless, the dataset contained 112120 scans where we found 2290 validated chest x-ray images. \n",
    "\n",
    "\n",
    "**Description of Validation Dataset:** \n",
    "Same as the training dataset but here we found 1430 validated x-ray images.\n",
    "\n",
    "\n",
    "### 5. Ground Truth\n",
    "source: https://www.kaggle.com/nih-chest-xrays/data\n",
    "The image labels are NLP extracted so there could be some erroneous labels but the NLP labeling accuracy is estimated to be >90%. Therefore the ground truth must go hand in hand with the radiologist. Also the labels indicated that in some cases the patients had more then one disease.  \n",
    "\n",
    "\n",
    "### 6. FDA Validation Plan\n",
    "\n",
    "**Patient Population Description for FDA Validation Dataset:**\n",
    "Gender can be both men and women and the sample must be bakanced. Age is until 120 years, with chest x-ray taken to examen thoracic pathologies.  \n",
    "\n",
    "**Ground Truth Acquisition Methodology:**\n",
    "we can use several radiologist identifying Pneumonia. (Silver standard)\n",
    "\n",
    "**Algorithm Performance Standard:**\n",
    "The accurary is 38%, while the F1 is around 35%. So it seems not so easy to come up with a good model and the training parameters requires lots of testing which resolve in lots of trial and error. I retrained the model many times and the training rate is definitely an important parameter. \n",
    "    * Precision is: 22%\n",
    "    * Recall is: 88%\n",
    "    * Threshold is: 38%\n",
    "    * F1 Score is: 35%\n",
    "    * Accuracy is: 38%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
